{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import functions as st\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "parcellation = 'Sch240'\n",
    "n_connectomes = '20'\n",
    "behaviour_list = ['APM','NART_IQ','Q1_TotalWords','Q6_TotalCorrect','CoC_abs_rev']\n",
    "#normalise_behav = True\n",
    "#reverse_behav = True\n",
    "regress_size = False\n",
    "CCApermutations = 1000\n",
    "MCA_components = 5\n",
    "CCA_components = 5\n",
    "outdir = '/Users/luke/Documents/Projects/StrokeNet/Docs/Figures/2020/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "136it [00:06, 19.48it/s]\n"
     ]
    }
   ],
   "source": [
    "behav_df, CM = st.load_data(parcellation=parcellation,\n",
    "                         n_connectomes=n_connectomes,\n",
    "                         behaviour_list=behaviour_list,\n",
    "                              load_nifti=False)\n",
    "\n",
    "#MNIcoords, networks, network_labels = st.get_atlas_info(parcellation=parcellation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare out of loop data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects= 80 , nodes= 240 , edges= 28680\n",
      "Edges included= 7779\n"
     ]
    }
   ],
   "source": [
    "# reshape connectivity data\n",
    "n_subs = np.shape(CM['Diff'])[2]\n",
    "n_nodes = np.shape(CM['Diff'])[0]\n",
    "n_edges = np.int((n_nodes*(n_nodes-1))/2)\n",
    "print('Subjects=',n_subs,', nodes=',n_nodes,', edges=',n_edges)\n",
    "\n",
    "X_full = np.zeros((n_subs,n_edges))\n",
    "index_upper = np.triu_indices(n_nodes, k=1)\n",
    "for subj in range(n_subs):\n",
    "    data = CM['Diff'][:,:,subj].copy()\n",
    "    X_full[subj,:] = data[index_upper].copy()\n",
    "\n",
    "# binarize edges\n",
    "X_full = X_full > 0\n",
    "\n",
    "# remove non informative features\n",
    "keep_features = np.sum(X_full,axis=0)>3\n",
    "X = X_full[:,keep_features]\n",
    "print('Edges included=',np.sum(keep_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = behav_df[behaviour_list].values\n",
    "y = y * -1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories [True] in column 1035 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e0504a4aef22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# individual loadings onto components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mmca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mind_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# and apply MCA to test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/prince/mca.py\u001b[0m in \u001b[0;36mrow_coordinates\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrow_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcolumn_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/prince/one_hot.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         return pd.SparseDataFrame(\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    730\u001b[0m                                        copy=True)\n\u001b[1;32m    731\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_transform_new\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;34m\"\"\"New implementation assuming categorical input\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;31m# validation of X happens in _check_X called by _transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0mX_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_int\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X, handle_unknown)\u001b[0m\n\u001b[1;32m    120\u001b[0m                     msg = (\"Found unknown categories {0} in column {1}\"\n\u001b[1;32m    121\u001b[0m                            \" during transform\".format(diff, i))\n\u001b[0;32m--> 122\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                     \u001b[0;31m# Set the problematic rows to an acceptable value and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found unknown categories [True] in column 1035 during transform"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm\n",
    "import prince\n",
    "\n",
    "#number of folds\n",
    "num_cvs = 5\n",
    "\n",
    "#number of iterations\n",
    "cv_iterations = 2\n",
    "\n",
    "# define cross validation scheme\n",
    "cv = KFold(n_splits=num_cvs,shuffle=True)\n",
    "\n",
    "#output variables\n",
    "r_avg = np.zeros((cv_iterations,np.shape(y)[1]))\n",
    "rs_avg = r_avg.copy()\n",
    "MAE_avg = r_avg.copy()\n",
    "Rsqr_avg = r_avg.copy()\n",
    "\n",
    "for j in tqdm(range(cv_iterations)):\n",
    "    \n",
    "    # variables for this iteration\n",
    "    r = np.zeros((num_cvs,np.shape(y)[1]))\n",
    "    rs = r.copy()\n",
    "    MAE = r.copy()\n",
    "    Rsqr = r.copy()\n",
    "\n",
    "    cv_count = 0\n",
    "    for train_index, test_index in cv.split(X):\n",
    "        \n",
    "        #organise the data into training and testing sets\n",
    "        X_train = X[train_index,:]\n",
    "        X_test  = X[test_index,:]\n",
    "        \n",
    "        y_train = y[train_index,:]\n",
    "        y_test = y[test_index,:]\n",
    "        \n",
    "        # trim X to informative features (X train needs to be applicable to X test)\n",
    "        \n",
    "        \n",
    "        # normalise y in train set\n",
    "        scaler = preprocessing.QuantileTransformer(n_quantiles=len(y_train)).fit(y_train)\n",
    "        y_train_scaled = scaler.transform(y_train)\n",
    "        \n",
    "        # and apply normalization to test set\n",
    "        y_test_scaled = scaler.transform(y_test)\n",
    "        \n",
    "        # perform MCA on x in train set\n",
    "        mca = prince.MCA(n_components=MCA_components).fit(X_train)\n",
    "\n",
    "        # individual loadings onto components\n",
    "        mca.ind_scores = mca.row_coordinates(X).values\n",
    "\n",
    "        # and apply MCA to test set\n",
    "        \n",
    "#         # do cca\n",
    "#         cv_cca = CCA(n_components=1)\n",
    "#         cv_cca.fit(X_train,y_train)\n",
    "\n",
    "#         # predict left out values\n",
    "#         y_pred = cv_cca.predict(X_test)\n",
    "\n",
    "#         # save predictions for this cv\n",
    "#         for i in range(np.shape(y)[1]):\n",
    "#             r[cv_count,i] = np.corrcoef(y[test_index,i],y_pred[:,i])[0,1]\n",
    "#             rs[cv_count,i] = spearmanr(y[test_index,i],y_pred[:,i])[0]\n",
    "#             MAE[cv_count,i] = mean_absolute_error(y[test_index,i],y_pred[:,i])\n",
    "#             Rsqr[cv_count,i] = r2_score(y[test_index,i],y_pred[:,i])\n",
    "#         cv_count = cv_count+1 \n",
    "\n",
    "#     # average predictions for this iteration\n",
    "#     r_avg[j,:] = np.mean(r,axis=0)\n",
    "#     rs_avg[j,:] = np.mean(rs,axis=0)\n",
    "#     MAE_avg[j,:] = np.mean(MAE,axis=0)\n",
    "#     Rsqr_avg[j,:] = np.mean(Rsqr,axis=0)\n",
    "# return r_avg,rs_avg,MAE_avg,Rsqr_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61111111, 0.6984127 , 0.98891884, 0.86507937, 0.71428571],\n",
       "       [0.03968254, 0.51587302, 0.26984127, 0.14285714, 0.00497713],\n",
       "       [0.61111111, 0.49206349, 0.88095238, 0.57936508, 0.36507937],\n",
       "       [0.        , 0.07142857, 0.03968254, 0.04761905, 0.73809524],\n",
       "       [0.23015873, 0.37301587, 0.55026455, 0.73809524, 0.23809524],\n",
       "       [0.61111111, 0.75396825, 0.41587302, 0.43650794, 0.8042328 ],\n",
       "       [0.46825397, 0.42063492, 0.87037037, 0.8968254 , 0.17777778],\n",
       "       [1.        , 0.75396825, 0.55555556, 0.51587302, 1.        ],\n",
       "       [0.31746032, 0.31746032, 0.22222222, 0.19047619, 0.62857143],\n",
       "       [0.46825397, 0.83333333, 0.71428571, 0.84126984, 0.76190476],\n",
       "       [1.        , 0.46031746, 0.9047619 , 0.80952381, 1.        ],\n",
       "       [0.12698413, 0.37301587, 0.42857143, 0.65079365, 0.26839827],\n",
       "       [0.03968254, 0.37301587, 0.3968254 , 0.19047619, 0.56613757],\n",
       "       [1.        , 0.42063492, 0.82010582, 0.53968254, 0.47619048],\n",
       "       [0.12698413, 0.96825397, 0.73015873, 0.53968254, 1.        ],\n",
       "       [0.78571429, 0.32804233, 0.81746032, 0.19047619, 1.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
